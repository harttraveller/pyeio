{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyEIO: Python Easy Input-Output","text":"<p><code>pyeio</code> is a Python library meant to simplify file IO processes. It standardizes the API for various file formats and types, and adds various ease-of-development features.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#usage","title":"Usage","text":""},{"location":"cli/","title":"CLI","text":""},{"location":"features/","title":"Feature Index","text":""},{"location":"man%20wc/","title":"Man wc","text":"<p>WC(1)                       General Commands Manual                      WC(1)</p> <p>NAME      wc \u2013 word, line, character, and byte count</p> <p>SYNOPSIS      wc --libxo [file ...]</p> <p>DESCRIPTION      The wc utility displays the number of lines, words, and bytes contained      in each input file, or standard input (if no file is specified) to the      standard output.  A line is defined as a string of characters delimited      by a \u27e8newline\u27e9 character.  Characters beyond the final \u27e8newline\u27e9      character will not be included in the line count.</p> <pre><code> A word is defined as a string of characters delimited by white space\n characters.  White space characters are the set of characters for which\n the iswspace(3) function returns true.  If more than one input file is\n specified, a line of cumulative counts for all the files is displayed on\n a separate line after the output for the last file.\n\n The following options are available:\n\n --libxo\n         Generate output via libxo(3) in a selection of different human\n         and machine readable formats.  See xo_parse_args(3) for details\n         on command line arguments.\n\n -L      Write the length of the line containing the most bytes (default)\n         or characters (when -m is provided) to standard output.  When\n         more than one file argument is specified, the longest input line\n         of all files is reported as the value of the final \u201ctotal\u201d.\n\n -c      The number of bytes in each input file is written to the standard\n         output.  This will cancel out any prior usage of the -m option.\n\n -l      The number of lines in each input file is written to the standard\n         output.\n\n -m      The number of characters in each input file is written to the\n         standard output.  If the current locale does not support\n         multibyte characters, this is equivalent to the -c option.  This\n         will cancel out any prior usage of the -c option.\n\n -w      The number of words in each input file is written to the standard\n         output.\n\n When an option is specified, wc only reports the information requested by\n that option.  The order of output always takes the form of line, word,\n byte, and file name.  The default action is equivalent to specifying the\n -c, -l and -w options.\n\n If no files are specified, the standard input is used and no file name is\n displayed.  The prompt will accept input until receiving EOF, or [^D] in\n most environments.\n\n If wc receives a SIGINFO (see the status argument for stty(1)) signal,\n the interim data will be written to the standard error output in the same\n format as the standard completion message.\n</code></pre> <p>ENVIRONMENT      The LANG, LC_ALL and LC_CTYPE environment variables affect the execution      of wc as described in environ(7).</p> <p>EXIT STATUS      The wc utility exits\u00a00 on success, and\u00a0&gt;0 if an error occurs.</p> <p>EXAMPLES      Count the number of characters, words and lines in each of the files      report1 and report2 as well as the totals for both:</p> <pre><code>       wc -mlw report1 report2\n\n Find the longest line in a list of files:\n\n       wc -L file1 file2 file3 | fgrep total\n</code></pre> <p>COMPATIBILITY      Historically, the wc utility was documented to define a word as a      \u201cmaximal string of characters delimited by ,  or       characters\u201d.  The implementation, however, did not handle non-printing      characters correctly so that \u201c\u00a0\u00a0^D^E\u00a0\u00a0\u201d counted as 6 spaces, while      \u201cfoo^D^Ebar\u201d counted as 8 characters.  4BSD systems after 4.3BSD modified      the implementation to be consistent with the documentation.  This      implementation defines a \u201cword\u201d in terms of the iswspace(3) function, as      required by IEEE Std 1003.2 (\u201cPOSIX.2\u201d). <pre><code> The -L option is a non-standard FreeBSD extension, compatible with the -L\n option of the GNU wc utility.\n</code></pre> <p>SEE ALSO      iswspace(3), libxo(3), xo_parse_args(3)</p> <p>STANDARDS      The wc utility conforms to IEEE Std 1003.1-2001 (\u201cPOSIX.1\u201d).</p> <p>HISTORY      A wc command appeared in Version\u00a01 AT&amp;T UNIX.</p> <p>macOS 14.6                      April 11, 2020                      macOS 14.6</p>"},{"location":"developer/todo/","title":"Todo","text":"<p>! a lot of these features should be split into different libraries/packages, this one should have minimal dependencies and just be really good at one thing</p>"},{"location":"developer/todo/#requirements","title":"Requirements","text":""},{"location":"developer/todo/#stretch-goals","title":"Stretch Goals","text":"<ul> <li>Reduce external dependencies to &gt; n (some low number) for all file formats</li> <li>Benchmark and try to speed up all operations.</li> <li>Use Result</li> </ul>"},{"location":"developer/todo/#features","title":"Features","text":""},{"location":"developer/todo/#dependencies","title":"Dependencies","text":""},{"location":"developer/todo/#security","title":"Security","text":"<ul> <li>pdfid - security analysis and deactivation of potentially malicious pdfs</li> <li>detection of whether archive is zip bomb</li> <li>google safebrowsing integration for downloading files, urls</li> <li>scrub/randomize exif metadata from images</li> <li>scrub/randomize generic metadata in files</li> <li>add some encryption utilities</li> </ul>"},{"location":"developer/todo/#analysis","title":"Analysis","text":"<ul> <li>in addition to estimating the number of lines in an uncompressed file, I should create an estimator for compressed files that factors in convergence of the compression ratio of text</li> </ul>"},{"location":"developer/todo/#unsorted","title":"Unsorted","text":"<ul> <li>check file integrity (hashes)</li> <li>check data integrity (parsable according to spec)</li> <li>fix data integrity (attempt to identify problem in corrupted data and fix it)</li> <li>get file size (raw and when in archive)<ul> <li>rough estimation for large files, return est. range?</li> <li>compute with certainty (much slower)</li> </ul> </li> <li>get in memory data size (pympler)</li> <li>estimate number of text lines in file<ul> <li>rough estimation for large files, return est. range?</li> <li>compute with certainty (much slower)<ul> <li>implement on disk cache of file/data hash so computation is accelerated for same file?</li> </ul> </li> </ul> </li> <li>estimate unpacked file size</li> <li>get file metadata (exif data, on disk metadata, pdf metadata)</li> <li>search disk for file</li> <li>use magic, chardet, langdetect(?) for identification of data/file properties/types</li> <li>(generic util) look at file/data entropy</li> <li>when downloading files, implement on disk caching for data based on hashes to avoid duplicative downloads?<ul> <li>would need to allow bypass</li> </ul> </li> <li>pydantic schema generation and validation</li> <li>automated data cleaning</li> <li>when there isn't any file extension, and the automatic loaders are used, the system should try and use python-magic to identify the file format</li> <li>add feature to write msgspec/pydantic models from data</li> <li>add feature to dynamically generate in memory pydantic models for validation<ul> <li>jsonschema validation?</li> </ul> </li> <li>do file format analysis using stack exchange sites/stack overflow data</li> <li>gather file metadata</li> <li>move files</li> <li>rename files</li> <li>grep in files/across files</li> <li>search files system</li> <li>get metadata about file system</li> <li>estimate/calc files/data size</li> <li>estimate/calc num lines</li> <li>estimate/calc num blocks</li> <li>estimate/calc num chars</li> <li>add ability to get hash of in memory object to <code>File</code> for use in both memory cache, and disk cache</li> </ul>"},{"location":"developer/todo/#maybe","title":"Maybe?","text":"<ul> <li>include CLI for various tools (typer?)<ul> <li>would definitely be useful for accessing rust code that is just useful and accelerated - eg: for checking the number of lines in a file</li> </ul> </li> <li>chaining of operations (pipe?)</li> <li>optional integration of web module with proxy service?</li> <li>fake user agent generation</li> <li>web crawling/evaluation with llm?</li> <li>create hierarchy of format sets - svg can be loaded by xml parser, md by txt, but pdf not by json, etc</li> <li>find files with data (search system), allow customization for handler that returns bool for positive identification<ul> <li>extend to crawling web/sites/domains</li> </ul> </li> <li>search engine for files on local machine</li> <li>search for images, use local vision model to assess contents<ul> <li>create and maintain index/cache to make future searches faster</li> <li>also can do for text and code</li> </ul> </li> <li>search for and handle (delete, export, list, etc) duplicates</li> <li>crawl domain to find files, add evaluator?</li> <li>encryption utilities</li> <li>host system analysis utilities</li> <li>system forensics and inference utilities</li> <li>add ability to detect link format for download and traverse to correct link/object, eg:</li> </ul> <pre><code># this should download video not html of youtube page\nweb.intelligent_download(url=\"https://www.youtube.com/watch?v=eHzoTLwx01E\", path=\"CES 2024.mp4\")\n\n# this should download file at https://raw.githubusercontent.com/harttraveller/pyeio/refs/heads/main/data/json/books.json\nweb.intelligent_download(url=\"https://github.com/harttraveller/pyeio/blob/main/data/json/books.json\", path=\"books.json\")\n</code></pre> <p>local disk operations:     path to mem (return) : open     path to mem (yield): read     mem to path (create/overwrite): save     mem to path (modify): ...</p> <p>web operations:     url to mem (return) : load     url to mem (yield) : stream     url to disk : pull</p> <ul> <li>to mem (open)<ul> <li>from disk (path) | disk_open | load</li> <li>from web (url) | web_open | wload</li> </ul> </li> <li>to disk (save)<ul> <li>from mem (object) | mem_save (save)</li> <li>from web (url) | web_save (wsave)</li> </ul> </li> </ul>"},{"location":"developer/todo/#pathto-mem","title":"path/to mem","text":"<p>url/to mem data/to disk url/to disk</p>"},{"location":"module/","title":"Module Reference","text":""},{"location":"notebook/","title":"Tutorial Notebooks","text":""},{"location":"notebook/json/","title":"JSON","text":"In\u00a0[1]: Copied! <pre># comment this out to use default `print` function\nfrom rich import print\n</pre> # comment this out to use default `print` function from rich import print In\u00a0[2]: Copied! <pre># import the necessary module\nfrom pyeio import json\n</pre> # import the necessary module from pyeio import json In\u00a0[3]: Copied! <pre>python_dictionary = json.parse(data='{\"color\":\"green\", \"count\": 3}')\npython_dictionary\n</pre> python_dictionary = json.parse(data='{\"color\":\"green\", \"count\": 3}') python_dictionary Out[3]: <pre>{'color': 'green', 'count': 3}</pre> In\u00a0[4]: Copied! <pre>json_string = json.serialize(python_dictionary, compact_serialization=False)\njson_string\n</pre> json_string = json.serialize(python_dictionary, compact_serialization=False) json_string Out[4]: <pre>'{\\n    \"color\": \"green\", \\n    \"count\": 3\\n}'</pre> In\u00a0[5]: Copied! <pre># load the data into memory\npython_dictionary = json.open(path=\"../../data/json/books.json\")\n# print the data\nprint(python_dictionary)\n</pre> # load the data into memory python_dictionary = json.open(path=\"../../data/json/books.json\") # print the data print(python_dictionary) <pre>{\n    'books': [\n        {\n            'id': 1,\n            'title': 'To Kill a Mockingbird',\n            'author': 'Harper Lee',\n            'year': 1960,\n            'genres': ['Fiction', 'Classic', 'Coming-of-age'],\n            'rating': 4.27,\n            'inStock': True\n        },\n        {\n            'id': 2,\n            'title': '1984',\n            'author': 'George Orwell',\n            'year': 1949,\n            'genres': ['Fiction', 'Dystopian', 'Political'],\n            'rating': 4.18,\n            'inStock': False\n        },\n        {\n            'id': 3,\n            'title': 'Pride and Prejudice',\n            'author': 'Jane Austen',\n            'year': 1813,\n            'genres': ['Fiction', 'Romance', 'Classic'],\n            'rating': 4.25,\n            'inStock': True\n        }\n    ],\n    'totalBooks': 3,\n    'lastUpdated': '2023-05-15T14:30:00Z'\n}\n</pre> In\u00a0[6]: Copied! <pre># defin sample data\npython_dictionary = {\"message\": \"hello world\", \"data\": [1, 2, 3, 4]}\n# save to local temp file\njson.save(data=python_dictionary, path=\"./temp/temp.json\", overwrite=True)\n</pre> # defin sample data python_dictionary = {\"message\": \"hello world\", \"data\": [1, 2, 3, 4]} # save to local temp file json.save(data=python_dictionary, path=\"./temp/temp.json\", overwrite=True) In\u00a0[7]: Copied! <pre># load the data from url\npython_dictionary = json.load(\n    url=\"https://raw.githubusercontent.com/harttraveller/pyeio/refs/heads/main/data/json/books.json\"\n)\n# print data\nprint(python_dictionary)\n</pre> # load the data from url python_dictionary = json.load(     url=\"https://raw.githubusercontent.com/harttraveller/pyeio/refs/heads/main/data/json/books.json\" ) # print data print(python_dictionary) <pre>{\n    'books': [\n        {\n            'id': 1,\n            'title': 'To Kill a Mockingbird',\n            'author': 'Harper Lee',\n            'year': 1960,\n            'genres': ['Fiction', 'Classic', 'Coming-of-age'],\n            'rating': 4.27,\n            'inStock': True\n        },\n        {\n            'id': 2,\n            'title': '1984',\n            'author': 'George Orwell',\n            'year': 1949,\n            'genres': ['Fiction', 'Dystopian', 'Political'],\n            'rating': 4.18,\n            'inStock': False\n        },\n        {\n            'id': 3,\n            'title': 'Pride and Prejudice',\n            'author': 'Jane Austen',\n            'year': 1813,\n            'genres': ['Fiction', 'Romance', 'Classic'],\n            'rating': 4.25,\n            'inStock': True\n        }\n    ],\n    'totalBooks': 3,\n    'lastUpdated': '2023-05-15T14:30:00Z'\n}\n</pre> In\u00a0[8]: Copied! <pre># download data to local file\njson.download(\n    url=\"https://raw.githubusercontent.com/harttraveller/pyeio/refs/heads/main/data/json/books.json\",\n    path=\"./temp/books.json\",\n    overwrite=True,\n)\n</pre> # download data to local file json.download(     url=\"https://raw.githubusercontent.com/harttraveller/pyeio/refs/heads/main/data/json/books.json\",     path=\"./temp/books.json\",     overwrite=True, )"},{"location":"notebook/json/#json","title":"JSON\u00b6","text":""},{"location":"notebook/json/#basic-usage","title":"Basic Usage\u00b6","text":""},{"location":"notebook/json/#parsing-serialized-data","title":"Parsing serialized data\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.parse</p>"},{"location":"notebook/json/#serializing-python-data","title":"Serializing python data\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.serialize</p>"},{"location":"notebook/json/#opening-a-file","title":"Opening a file\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.open</p>"},{"location":"notebook/json/#saving-data-to-a-file","title":"Saving data to a file\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.save</p>"},{"location":"notebook/json/#loading-data-from-a-url","title":"Loading data from a URL\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.load</p>"},{"location":"notebook/json/#downloading-data-at-a-url-to-a-file","title":"Downloading data at a URL to a file\u00b6","text":"<p>Reference: https://harttraveller.github.io/pyeio/module/pyeio.json/#pyeio.json.download</p>"},{"location":"notebook/json/#meta-module","title":"Meta Module\u00b6","text":"<p>TODO</p>"},{"location":"notebook/jsonl/","title":"JSONL","text":""},{"location":"notebook/jsonl/#jsonl","title":"JSONL\u00b6","text":""},{"location":"notebook/toml/","title":"TOML","text":""},{"location":"notebook/toml/#toml","title":"TOML\u00b6","text":""},{"location":"notebook/yaml/","title":"YAML","text":""},{"location":"notebook/yaml/#yaml","title":"YAML\u00b6","text":""},{"location":"notebook/zst/","title":"ZST","text":""},{"location":"notebook/zst/#zst","title":"ZST\u00b6","text":""}]}